# Human–AI Interaction Diagram Suite

This folder contains conceptual diagrams that illustrate core cognitive and
behavioural dynamics in human–AI interaction. These models support the research
deep dives on metacognition, interpretability, agency, and cognitive diversity.

## Diagram Index

- **Trust Calibration Loop**  
  Shows how humans update trust after interpreting AI outputs.  
  [`trust-calibration-loop.md`](./trust-calibration-loop.md)

- **Cognitive Load Flow**  
  Illustrates how mental effort increases or decreases depending on explanation clarity.  
  [`cognitive-load-flow.md`](./cognitive-load-flow.md)

- **Explanation Misalignment Flow**  
  Captures how mismatched AI explanations lead to misunderstanding or incorrect actions.  
  [`explanation-misalignment-flow.md`](./explanation-misalignment-flow.md)
