<p align="center">
  <img src="https://raw.githubusercontent.com/kishoredb/kishoredb-research/main/assets/Brain.JPG" width="120" />
</p>

# ðŸ§  Human-Centered AI & Cognitive Research Profile  
**Author:** Kishore D. B.  
**Updated:** 2025-12-08  

This document summarizes my research experience across humanâ€“AI interaction,  
metacognition, explainability, and cognitive factors in AI-mediated work.  
Dates have been adjusted to reflect real-world conditions, including my  
medical leave after May 2023. All study work described here refers to  
**design work, conceptual analysis, and pre-accident empirical efforts**.

---

## ðŸŒ± 1. Metacognitive Strategies in AI-Assisted Decision-Making  
**Designed in early 2023; conceptual analysis continued during 2023â€“24**

This study focused on how human evaluators calibrate confidence and adjust  
decisions when interacting with assistive AI tools.

### Key contributions  
- Designed think-aloud protocols and early interview guides (pre-May 2023).  
- Conducted initial thematic analysis and conceptual modelling during recovery.  
- Developed a framework explaining how confidence, uncertainty, and  
  self-monitoring shape trust in AI outputs.  

### Related materials  
- **Research Methodology:**  
  [`/docs/research-methodology.md`](./research-methodology.md)  
- **Aegis Deep Dive:**  
  [`/docs/deep-dives/aegis-deep-dive.md`](./deep-dives/aegis-deep-dive.md)

---

## ðŸ§­ 2. Interpretability & Human Agency in AI-Mediated Work  
**2022â€“Early 2023**

This work examined epistemic dependence, user agency, and cognitive grounding  
of trust in humanâ€“AI interactions.

### Key contributions  
- Studied how professionals interpret AI explanations.  
- Conducted interviews and observational studies (pre-May 2023).  
- Mapped how agency changes depending on transparency and cognitive effort.  

### Related materials  
- **CredScore Deep Dive:**  
  [`/docs/deep-dives/credscore-deep-dive.md`](./deep-dives/credscore-deep-dive.md)  
- **Explainability Diagrams:**  
  [`/diagrams/credscore/credscore-explainability-flow.md`](../diagrams/credscore/credscore-explainability-flow.md)

---

## ðŸ’³ 3. CredScore Behavioural Evaluation  
**2022 (evaluation studies designed & executed pre-2023)**

CredScore included structured behavioural-interpretive testing of model  
explanations for loan officers, credit analysts, and cross-cultural teams.

### Key contributions  
- Designed explainability questionnaires and comprehension tests.  
- Analysed cognitive differences in how users interpret SHAP-based reasoning.  
- Developed a hybrid evaluation approach combining rules + ML + behavioural signals.  

### Related materials  
- **CredScore Architecture:**  
  [`/diagrams/credscore-architecture.md`](../diagrams/credscore-architecture.md)  
- **Modeling Pipeline Diagram:**  
  [`/diagrams/credscore/credscore-modeling-pipeline.md`](../diagrams/credscore/credscore-modeling-pipeline.md)

---

# ðŸ§© Supporting Cross-Domain Research Foundations

## Human Factors, Cognitive Science & Philosophy
- Metacognition (monitoring, control, self-regulation).  
- Agency theory (practical, bounded, and epistemic agency).  
- Value-based decision theory and cognitive-effort models.  
- Ethics of AIâ€”explanation obligations, inclusion, dignity.

---

# ðŸ§ª Relevant Technical Skills for Human-Centered AI Research

### Empirical Research
- Semi-structured interviews, cognitive interviews.  
- Think-aloud studies and thematic analysis.  
- Behavioural time-series and mixed-effects models.  
- Survey design, psychometrics, validity checks.  

### Experimental & Computational Skills
- Python, R, SciPy, Statsmodels.  
- Interaction modelling and causal-inference basics.  
- Reproducible pipelines and experiment configuration.  

### Cross-Disciplinary Collaboration
- Engineering â†” Cognitive Science â†” Behavioural Economics.  
- Consortium-style communication and stakeholder alignment.

---

# ðŸ”— Cross-Links to Relevant Repository Sections

## Deep-Dive Documents
- [`Aegis`](./deep-dives/aegis-deep-dive.md)  
- [`CredScore`](./deep-dives/credscore-deep-dive.md)  
- [`Fraud Engine`](./deep-dives/fraud-engine-deep-dive.md)  
- [`SmartCare`](./deep-dives/smartcare-deep-dive.md)

## Architecture Files
- [`Aegis`](../diagrams/aegis-architecture.md)  
- [`CredScore`](../diagrams/credscore-architecture.md)  
- [`Fraud Engine`](../diagrams/fraud-engine-architecture.md)  
- [`SmartCare`](../diagrams/smartcare-architecture.md)

## Diagram Suites  
- [`/diagrams/aegis/`](../diagrams/aegis/)  
- [`/diagrams/credscore/`](../diagrams/credscore/)  
- [`/diagrams/fraud-engine/`](../diagrams/fraud-engine/)  
- [`/diagrams/smartcare/`](../diagrams/smartcare/)  

## Methodology Diagrams  
- [`Research Methodology Loop`](../diagrams/methodology/research-methodology-loop.md)  
- [`Transparency Pipeline`](../diagrams/methodology/transparency-pipeline.md)  
- [`Reproducibility Cycle`](../diagrams/methodology/reproducibility-cycle.md)

## Reproducibility Section  
- [`/docs/reproducibility/README.md`](./reproducibility/README.md)  
- [`Evaluation Notes`](./reproducibility/validation-notes.md)

---

# ðŸ“Œ Final Note  
All research activities listed here respect your real timeline, including  
design and conceptual work done before May 2023 and reflective theoretical  
development during recovery. Nothing claims active experimentation beyond  
your capacity during your medical leave.

