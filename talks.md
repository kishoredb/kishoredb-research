# ðŸŽ¤ Talks & Presentations  
**Author:** Kishore D. B.  
**Version:** 1.0  
**Updated:** 2025-12-01  

This page lists invited talks, internal/external presentations, and technical  
sessions delivered across scientific ML, AI systems engineering, and  
computational workflows.

---

## 1. DevSecOps Culture for AI & Computational Engineering  
**Event:** Global Engineering Summit  
**Year:** 2022  
**Type:** Invited Talk  
**Domain:** AI engineering, platform governance, reliability  

Discussed frameworks for integrating observability, explainability, traceability,  
and security controls into end-to-end AI and HPC deployment workflows. Highlighted  
the importance of transparent pipelines for reproducibility and scientific-grade  
engineering.

---

## 2. Explainable AI for Simulation Workflows  
**Event:** Finastra Innovation Forum  
**Year:** 2023  
**Type:** Invited Presentation  
**Domain:** Scientific ML, XAI  

Presented explainable ML workflows for simulation-driven decision systems,  
including SHAP-based reasoning layers, gradient analysis, sensitivity studies,  
and integrated visualization modules used for model introspection.

---

## 3. Applied Scientific ML for Risk Intelligence  
**Event:** Internal Research ADA Session  
**Year:** 2021  
**Type:** Technical Presentation  
**Domain:** Risk modeling, scientific ML  

Introduced a modular ML approach for risk intelligence models focused on  
numerical stability, calibration, reliability, and regulatory explainability.  
Covered integration with simulation-based risk engines.

---

## 4. Cloud-Native HPC Pipelines: Orchestration & Reproducibility  
**Event:** Internal Engineering Knowledge Share  
**Year:** 2023  
**Type:** Engineering Deep-Dive Session  
**Domain:** HPC, cloud-native systems  

Presented distributed orchestration patterns for simulation workloads and model  
sweeps using Kubernetes, Argo Workflows, and autoscaling mechanisms. Emphasized  
experiment reproducibility, metadata capture, and run provenance.

---

## 5. Scientific Visualization & ML Interpretability for Education  
**Event:** Learning & Innovation Seminar  
**Years:** 2021â€“2022  
**Type:** Workshop / Curriculum Session  
**Domain:** Education, visualization, XAI  

Conducted sessions demonstrating how scientific visualization techniques improve  
learner understanding of simulation outputs and ML explainability concepts, using  
custom Jupyter-based teaching modules.

---

## Summary  
These talks highlight technical leadership and research communication across  
scientific ML, simulation workflows, platform engineering, and reproducible  
computational systems.

